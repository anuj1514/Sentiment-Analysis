{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2157,"sourceType":"datasetVersion","datasetId":18}],"dockerImageVersionId":30474,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this project, I will show two different approaches to sentiment analysis by using VADER Sentiment Analysis Tool and RobertA pretrained language model. \n\nI will start with importing the necessary packages. The dataset has almost 600k datapoints. To be able to save some time, I have chosen only the first 1000 datapoints. Otherwise, it can take up to 15 minutes to run the models in entire dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot') #it sets the style of the plots\n\ndf= pd.read_csv(\"../input/amazon-fine-food-reviews/Reviews.csv\")\ndf = df.head(1000)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:39:15.350695Z","iopub.execute_input":"2023-05-09T09:39:15.351064Z","iopub.status.idle":"2023-05-09T09:39:25.801406Z","shell.execute_reply.started":"2023-05-09T09:39:15.351032Z","shell.execute_reply":"2023-05-09T09:39:25.800451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:39:25.812366Z","iopub.execute_input":"2023-05-09T09:39:25.813388Z","iopub.status.idle":"2023-05-09T09:39:25.821977Z","shell.execute_reply.started":"2023-05-09T09:39:25.81334Z","shell.execute_reply":"2023-05-09T09:39:25.820504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will make a basic visualization of each score and their abundancy with a bar plot. ","metadata":{}},{"cell_type":"code","source":"ax = df[\"Score\"].value_counts().sort_index().plot(kind= \"bar\", title= \"Count of Review Scores\", figsize=(5,5))\nax.set_xlabel(\"Review Scores\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=0);","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:39:29.810653Z","iopub.execute_input":"2023-05-09T09:39:29.811153Z","iopub.status.idle":"2023-05-09T09:39:30.192933Z","shell.execute_reply.started":"2023-05-09T09:39:29.811106Z","shell.execute_reply":"2023-05-09T09:39:30.191726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VADER Sentiment Analysis\n\nVADER is Valence Aware Dictionary and sEntiment Reasoner in short. VADER is a rule-based sentiment analysis tool that uses a lexicon of words and phrases with associated sentiment scores to analyze the sentiment of a text. Additionally, it takes into account the intensity of sentiment and the presence of negation in a sentence to provide a more accurate sentiment analysis result. \n\nI use the SentimentIntensityAnalyzer class from nltk.sentiment module, which is an NLTK implementation of VADER.","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nfrom tqdm.notebook import tqdm\nsia= SentimentIntensityAnalyzer()\nsia.polarity_scores(\"I am very sad!\")","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:39:32.948872Z","iopub.execute_input":"2023-05-09T09:39:32.949246Z","iopub.status.idle":"2023-05-09T09:39:33.903487Z","shell.execute_reply.started":"2023-05-09T09:39:32.949215Z","shell.execute_reply":"2023-05-09T09:39:33.90223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen above, polarity_scores method gives four parameters: Negativity, neutrality, positivity and compound scores. The first three I believe quite clear, but to clarify the compound score: It basically positions the sentiment between -1 and 1. 1 is the most positive and -1 is the most negative in the spectrum. Now, I write a loop to calculate the each score for each sentiment and I will store the results in a dictionary.","metadata":{}},{"cell_type":"code","source":"res={}\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    text= row[\"Text\"]\n    myid= row[\"Id\"]\n    res[myid] = sia.polarity_scores(text)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:41:40.670175Z","iopub.execute_input":"2023-05-09T09:41:40.670725Z","iopub.status.idle":"2023-05-09T09:41:41.836837Z","shell.execute_reply.started":"2023-05-09T09:41:40.670677Z","shell.execute_reply":"2023-05-09T09:41:41.835643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To work easily on the data, I need to convert the dictionary to dataframe. With the \".T\" attribute, I will transpose the dataframe to match the shape of df. Then, I will combine the VADER results with df. One important point is here that to be able to merge them togther, I need a column with the same name in both dataframes. So, I change the name of the index column of vaders result to \"Id\", so it matches with the \"Id\" column in df. ","metadata":{}},{"cell_type":"code","source":"vaders = pd.DataFrame(res).T\nvaders= vaders.reset_index().rename(columns={\"index\": \"Id\"})\nvaders= vaders.merge(df, how=\"left\")\nvaders.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:41:47.902537Z","iopub.execute_input":"2023-05-09T09:41:47.903616Z","iopub.status.idle":"2023-05-09T09:41:47.954267Z","shell.execute_reply.started":"2023-05-09T09:41:47.903559Z","shell.execute_reply":"2023-05-09T09:41:47.953213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, I have results of VADER Sentiment analysis and the scores given by the customers. I will check, what is the distribution of Compound Score according to Amazon Scores. For that, I use barplot from seaborn library. ","metadata":{}},{"cell_type":"code","source":"ax = sns.barplot(data=vaders, x=\"Score\", y=\"compound\")\nax.set_title(\"Compound Score vs Amazon Score\")\nax.set_xlabel(\"Amazon Score\")\nax.set_ylabel(\"Compound Score\");","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:41:51.608175Z","iopub.execute_input":"2023-05-09T09:41:51.608638Z","iopub.status.idle":"2023-05-09T09:41:52.073008Z","shell.execute_reply.started":"2023-05-09T09:41:51.608595Z","shell.execute_reply":"2023-05-09T09:41:52.071855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Compound score seems to be relevant to the Amazon scores in which 1 has negative values in compound score, while 5 has the highest positive compound score. Finally, I will plot the same barplots this time with negative, positive and neutral scores vs Amazon score.","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(12, 3))\nsns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])\nsns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])\nsns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])\naxs[0].set_title('Positive')\naxs[1].set_title('Neutral')\naxs[2].set_title('Negative')\naxs[0].set_xlabel(\"Amazon Score\")\naxs[1].set_xlabel(\"Amazon Score\")\naxs[2].set_xlabel(\"Amazon Score\")\naxs[0].set_ylabel(\"Positive Score\")\naxs[1].set_ylabel(\"Neutral Score\")\naxs[2].set_ylabel(\"Negative Score\")\nplt.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:41:55.052716Z","iopub.execute_input":"2023-05-09T09:41:55.053532Z","iopub.status.idle":"2023-05-09T09:41:56.113908Z","shell.execute_reply.started":"2023-05-09T09:41:55.053478Z","shell.execute_reply":"2023-05-09T09:41:56.112652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The barplots seem to be logical. Especially, when I look at the positive score vs Amazon score, I see that score 1 has the lowest positive score as it should be and vice versa for negative score. ","metadata":{}},{"cell_type":"markdown","source":"#### RobertA Pretrained Language Model:\n\nAt the second part of the project, I will use RobertA for sentiment analysis.\n\nRobertA is Robustly Optimized BERT Pretraining Approach in short. It is a state-of-the-art pretrained language model based on the Transformer architecture. RobertA is usually used for more complex NLP tasks such as language generation or question answering, however, can be used also for sentiment analysis. To be able to use this model, first I will import the necessary classes and the softmax function.","metadata":{"execution":{"iopub.status.busy":"2023-05-07T16:26:29.615288Z","iopub.execute_input":"2023-05-07T16:26:29.615664Z","iopub.status.idle":"2023-05-07T16:26:29.620476Z","shell.execute_reply.started":"2023-05-07T16:26:29.615638Z","shell.execute_reply":"2023-05-07T16:26:29.619261Z"}}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nfrom scipy.special import softmax","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:42:06.543906Z","iopub.execute_input":"2023-05-09T09:42:06.544308Z","iopub.status.idle":"2023-05-09T09:42:08.700009Z","shell.execute_reply.started":"2023-05-09T09:42:06.544277Z","shell.execute_reply":"2023-05-09T09:42:08.698936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I use the pre-trained sentiment analysis model based on the Twitter RoBERTa architecture from the Hugging Face Transformers library.\n\nThe model can be accessed from the link below: \n\nhttps://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment","metadata":{}},{"cell_type":"code","source":"MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:42:10.350119Z","iopub.execute_input":"2023-05-09T09:42:10.35078Z","iopub.status.idle":"2023-05-09T09:42:30.500953Z","shell.execute_reply.started":"2023-05-09T09:42:10.350743Z","shell.execute_reply":"2023-05-09T09:42:30.500029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, as in VADER analyis, I will write a function to acquire relevant parameters from RobertA, as well. So, that I can make a direct comparison between the two. \n\nFirst, I tokenize the text, breaking down the text into smaller pieces called tokens. Then, with \"return_tensors=\"pt\", I convert these tokens to pytorch tensors, which are the representative of numerical data. In other words, we associate these tokens (words, subwords) with numbers, so that the model can make mathematical calculations. Then, with the model, I provide the text to be analyzed to RobertA and get the output. I convert the output to numpy array and transform it into the probability scores such as \"negative, positive and neutral\". I store all in a dictionary.","metadata":{}},{"cell_type":"code","source":"def polarity_scores_roberta(exp):\n    encoded_text = tokenizer(exp, return_tensors=\"pt\")\n    output = model(**encoded_text)\n    scores = output[0][0].detach().numpy()\n    scores=softmax(scores)\n    scores_dict = {\n        \"roberta_neg\" : scores [0],\n        \"roberta_neu\" : scores[1],\n        \"roberta_pos\" : scores[2]\n    }\n    return (scores_dict)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:42:47.560402Z","iopub.execute_input":"2023-05-09T09:42:47.561784Z","iopub.status.idle":"2023-05-09T09:42:47.570705Z","shell.execute_reply.started":"2023-05-09T09:42:47.561733Z","shell.execute_reply":"2023-05-09T09:42:47.569065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With a another loop, I will apply it to the entire dataset combined with VADER analysis results. While the code is running, it gets broken for certain Ids, where RobertA encounters with a problem to process. To skip those datapoints, I add RuntimeError exception as a simple debugging so that it runs smoothly.","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nres={}\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    try:\n        text= row[\"Text\"]\n        myid= row[\"Id\"]\n        vader_result = sia.polarity_scores(text)\n        vader_result_rename = {}\n        for key, value in vader_result.items():\n            vader_result_rename[f\"vader_{key}\"] = value\n        roberta_result = polarity_scores_roberta(text)\n        both = {**vader_result_rename, **roberta_result}\n        res[myid] = both\n    except RuntimeError:\n        print(f\"Broke for id {myid}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:42:57.203359Z","iopub.execute_input":"2023-05-09T09:42:57.203814Z","iopub.status.idle":"2023-05-09T09:46:16.15657Z","shell.execute_reply.started":"2023-05-09T09:42:57.20378Z","shell.execute_reply":"2023-05-09T09:46:16.15503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As in VADER, I convert the dictionary to dataframe and I combine it with df. ","metadata":{}},{"cell_type":"code","source":"df_final = pd.DataFrame(res).T\ndf_final= df_final.reset_index().rename(columns={\"index\": \"Id\"})\ndf_final= df_final.merge(df, how=\"left\")\ndf_final.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:51:17.995506Z","iopub.execute_input":"2023-05-09T09:51:17.995889Z","iopub.status.idle":"2023-05-09T09:51:18.051289Z","shell.execute_reply.started":"2023-05-09T09:51:17.995861Z","shell.execute_reply":"2023-05-09T09:51:18.050375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparison of RobertA and VADER:\n\nI will use pairplot from the seaborn library to visualize the relationsship between two variables, which are sentiment scores from both RobertA and VADER.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data=df_final, vars=[\"vader_neg\", \"vader_neu\", \"vader_pos\", \"roberta_neg\", \"roberta_neu\", \"roberta_pos\"], \n             hue=\"Score\", palette=\"tab10\");","metadata":{"execution":{"iopub.status.busy":"2023-05-09T09:51:26.043799Z","iopub.execute_input":"2023-05-09T09:51:26.044203Z","iopub.status.idle":"2023-05-09T09:51:42.332601Z","shell.execute_reply.started":"2023-05-09T09:51:26.044171Z","shell.execute_reply":"2023-05-09T09:51:42.331047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When I look at the plots, we can make an overall prediction about the performance of RobertA and VADER: RobertA seems to cluster scores better compared to VADER. \n\nNow, I will try to determine the most confusing sentiments for each, RobertA and VADER for Score 1 and 5.","metadata":{}},{"cell_type":"code","source":"df_final.query(\"Score == 5\").sort_values(\"vader_neg\", ascending= False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T22:11:31.891241Z","iopub.execute_input":"2023-05-08T22:11:31.891728Z","iopub.status.idle":"2023-05-08T22:11:31.912686Z","shell.execute_reply.started":"2023-05-08T22:11:31.891695Z","shell.execute_reply":"2023-05-08T22:11:31.911631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.query(\"Score == 5\").sort_values(\"roberta_neg\", ascending= False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T22:11:34.196343Z","iopub.execute_input":"2023-05-08T22:11:34.196745Z","iopub.status.idle":"2023-05-08T22:11:34.210107Z","shell.execute_reply.started":"2023-05-08T22:11:34.196715Z","shell.execute_reply":"2023-05-08T22:11:34.208758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.query(\"Score == 1\").sort_values(\"vader_pos\", ascending= False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T22:11:36.033129Z","iopub.execute_input":"2023-05-08T22:11:36.033781Z","iopub.status.idle":"2023-05-08T22:11:36.044135Z","shell.execute_reply.started":"2023-05-08T22:11:36.033745Z","shell.execute_reply":"2023-05-08T22:11:36.043312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.query(\"Score == 1\").sort_values(\"roberta_pos\", ascending= False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-08T22:11:38.59319Z","iopub.execute_input":"2023-05-08T22:11:38.593684Z","iopub.status.idle":"2023-05-08T22:11:38.60631Z","shell.execute_reply.started":"2023-05-08T22:11:38.593644Z","shell.execute_reply":"2023-05-08T22:11:38.60488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, overall RobertA seems to do better based on the graphical demonstration, however, we see also that ironic sentences decreases the accuracy of the models, since the model cannot interpret and conclude it as irony. ","metadata":{}}]}